{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9EN4E7Xb4lnMRMcyQfoXx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simeonbetapudi/DeepLearningAIEthics/blob/main/LeaderboardCompetition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGWCNTLQ17WE",
        "outputId": "a7ec9a98-d208-4457-9810-6a291509bab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: bigframes 2.23.0\n",
            "Uninstalling bigframes-2.23.0:\n",
            "  Successfully uninstalled bigframes-2.23.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Uninstall Colab's bigframes because it conflicts with other installs\n",
        "%pip uninstall -y bigframes\n",
        "# Install Lightning, also let's use \"rich\" progress bars\n",
        "%pip install -Uqq lightning wandb rich einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim, utils\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, RandomAffine, RandomErasing\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "# Not advocating Lightning over raw pytorch, but it offers some useful abstractions\n",
        "import lightning as L\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "from lightning.pytorch.callbacks import RichProgressBar\n",
        "import wandb\n",
        "import numpy as np\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "s944-VoW2tgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optional: define additional data augmentation transformers for the dataloader\n",
        "train_transforms = torchvision.transforms.Compose([\n",
        "    ToTensor(),\n",
        "    # uncomment next lines for extra augmentations\n",
        "    #RandomAffine(degrees=15, translate=(0.1, 0.1)),\n",
        "    #RandomErasing(p=0.2, scale=(0.02, 0.1))\n",
        "])\n",
        "\n",
        "train_ds = MNIST(root='./data', train=True,  download=True, transform=train_transforms)\n",
        "test_ds  = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
        "val_ds = test_ds  #alias val for test\n",
        "print(f\"Data set lengths: train: {len(train_ds)}, test: {len(test_ds)}\")\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128   # could make this bigger; note for MNIST on Colab we're disk-speed limited, not GPU-limited\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=2, shuffle=True, persistent_workers=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, num_workers=2, shuffle=False, persistent_workers=True)\n",
        "val_dl = test_dl # alias val <--> test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYaC1K3c2y0y",
        "outputId": "374d2c33-4cfd-4b44-c564-fc5d63156cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 481kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.36MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.43MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set lengths: train: 60000, test: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Code for `show_xs` visualization tool\n",
        "def show_xs(xs, show_stats=True):\n",
        "    \"\"\"A little utility to show one or more images\"\"\"\n",
        "    if type(xs) is not list: xs = list(xs)\n",
        "    ncols = len(xs)\n",
        "    fig, axs = plt.subplots(figsize=(3*ncols,2), ncols=ncols, squeeze=False)\n",
        "    ax = axs.ravel()\n",
        "    for col, x in enumerate(xs):\n",
        "        if len(x.shape)>2: x = x[0] # remove any batch dimension\n",
        "        if show_stats:\n",
        "            if ncols > 1: print(f\"col {col}: \",end=\"\")\n",
        "            print(f\"x.shape = {tuple(x.shape)}, min(x) = {torch.min(x)}, max(x) = {torch.max(x)}\")\n",
        "        digit = ax[col].imshow(x.detach().cpu().numpy(), cmap='gray')\n",
        "        fig.colorbar(digit, ax=ax[col])\n",
        "    plt.show()\n",
        "\n",
        "x, y = next(iter(train_dl))   # pick a few elements from the dataset\n",
        "print(f\"y (target) = {y[:4]} \")\n",
        "\n",
        "show_xs(x[:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "cellView": "form",
        "id": "jouzpUh923K_",
        "outputId": "1d5bf6c8-c770-43c3-fa3c-dabd94783762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y (target) = tensor([7, 4, 4, 3]) \n",
            "col 0: x.shape = (28, 28), min(x) = 0.0, max(x) = 1.0\n",
            "col 1: x.shape = (28, 28), min(x) = 0.0, max(x) = 1.0\n",
            "col 2: x.shape = (28, 28), min(x) = 0.0, max(x) = 1.0\n",
            "col 3: x.shape = (28, 28), min(x) = 0.0, max(x) = 0.9960784316062927\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x200 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title `test_inference` visualization code\n",
        "@torch.no_grad()\n",
        "def test_inference(model, idx=None, return_fig=False):\n",
        "    import inspect\n",
        "    model.eval()\n",
        "    if idx is None: idx = torch.randint(len(test_ds), (1,))[0]\n",
        "    if isinstance(idx, int): idx = [idx]\n",
        "    elif isinstance(idx, range): idx = list(idx)\n",
        "    x_batch = torch.stack([test_ds[i][0] for i in idx]).to(model.device)  # images\n",
        "    y_batch = torch.tensor([test_ds[i][1] for i in idx]).to(model.device) # labels\n",
        "    if not model.use_conv: x_batch = x_batch.view(x_batch.size(0), -1)\n",
        "    if 1==len(inspect.signature(model.forward).parameters): # for ae or vae\n",
        "        result = model.forward(x_batch)\n",
        "    else:                                                   # c-vae (later in lesson)\n",
        "        cond = F.one_hot(y_batch, num_classes=10).float()\n",
        "        result = model.forward(x_batch, cond)\n",
        "    z, recon = result[:2]\n",
        "    recon = recon.view(len(idx), 28, 28)\n",
        "    fig, axs = plt.subplots(2, len(idx), figsize=(3*len(idx), 4))\n",
        "    if len(idx) == 1: axs = axs.reshape(2, 1)\n",
        "    for i in range(len(idx)):\n",
        "        axs[0,i].imshow(x_batch[i].view(28,28).cpu(), cmap='gray')\n",
        "        axs[1,i].imshow(recon[i].cpu(), cmap='gray')\n",
        "        if i == 0:\n",
        "            axs[0,0].set_ylabel('Input', fontsize=12)\n",
        "            axs[1,0].set_ylabel('Reconstruction', fontsize=12)\n",
        "    model.train()\n",
        "    if return_fig: return fig\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zd3h3zHW6NWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"Double convolution block used in U-Net\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_channels, out_channels))\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, 2, stride=2)\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)  # x1 from decoder path, x2 is skip connection from encoder\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)  # Concatenate skip connection (key U-Net feature!)\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "-YFEfnU7WmZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetDown(nn.Module):\n",
        "  def __init__(self, n_channels=1, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, features[0])\n",
        "        self.downs = nn.ModuleList([Down(features[i], features[i+1]) for i in range(len(features)-1)])\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_mu = nn.Linear(features[-1] * 4 * 4, latent_dim)  # example for 4x4 spatial size\n",
        "        self.fc_logvar = nn.Linear(features[-1] * 4 * 4, latent_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "        skip_connections = []\n",
        "        x = self.inc(x)\n",
        "        skip_connections.append(x)\n",
        "\n",
        "        for down in self.downs:  # Downsampling path\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "\n",
        "        skip_connections = skip_connections[:-1]  # Remove last (bottleneck)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "\n",
        "        return mu, logvar, skip_connections\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "   def __init__(self, n_channels=1, n_classes=1, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "\n",
        "        self.fc = nn.Linear(latent_dim, features[-1] * 4 * 4)  # mirror encoder\n",
        "        self.unflatten = nn.Unflatten(1, (features[-1], 4, 4))\n",
        "        self.ups = nn.ModuleList([Up(features[len(features)-1-i], features[len(features)-2-i]) for i in range(len(features)-1)])\n",
        "        self.outc = nn.Conv2d(features[0], n_classes, 1)\n",
        "\n",
        "  def forward(self, bottleneck, skip_connections)\n",
        "        x = self.fc(bottleneck)\n",
        "        x = self.unflatten(x)\n",
        "\n",
        "        for i, up in enumerate(self.ups):  # Upsampling path with skip connections\n",
        "            skip = skip_connections[-(i+1)]\n",
        "            x = up(x, skip)\n",
        "\n",
        "        return torch.sigmoid(self.outc(x))"
      ],
      "metadata": {
        "id": "USeDuCycWl_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instead of nn.Module, we use L.LightningModule\n",
        "class VAEModel(nn.module):\n",
        "    def __init__(self,\n",
        "                 latent_dim=3,    # dimensionality of the latent space. bigger=less compression, better reconstruction\n",
        "                 features=[64,128,256,512],  # intermediate/hidden layers in our simple encoder/decoder\n",
        "                 act = nn.LeakyReLU,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        # VAE encoder outputs two values, for mean and variance\n",
        "        self.encoder = UNetDown(n_channels=1, features=features)\n",
        "\n",
        "        # VAE decoder is exactly same as vanilla AE\n",
        "        self.decoder = UNetUp(n_channels=1, n_classes=1, features=features)\n",
        "\n",
        "        self.use_conv = True\n",
        "        self.latent_dim, self.n_hid, self.act = latent_dim, n_hid, act # save config for archival purposes\n",
        "\n",
        "    def reparam_sample(self, mu, log_var):\n",
        "        \"this yields a data value by sampling from the learned gaussian distribution of latents\"\n",
        "        std = torch.exp(0.5*log_var).sqrt() # the 0.5 is an optional, tunable rescaling factor.\n",
        "        noise = torch.randn_like(std)       # the gaussian distribution we sample from\n",
        "        return mu + std * noise\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        i_half = z.shape[-1]//2\n",
        "        mu, log_var = z[:,:i_half],  z[:,i_half:]\n",
        "        z_hat = self.reparam_sample(mu, log_var)\n",
        "        x_hat = self.decoder(z_hat)\n",
        "        return z, x_hat, mu, log_var, z_hat # order chosen to preserve earlier model's outputs of z, x_hat\n",
        "\n",
        "\n",
        "    def pred_and_log(self, batch, batch_idx, log_prefix=''):\n",
        "        \"the basic task: make predictions, compute loss, and send to logging system\"\n",
        "        x, y = batch\n",
        "        x = x.view(x.size(0), -1)  # flatten for linear layer\n",
        "        z, x_hat, mu, log_var, z_hat = self.forward(x)\n",
        "\n",
        "        #recon_loss = nn.functional.mse_loss(x_hat, x)\n",
        "        recon_loss = nn.functional.binary_cross_entropy(x_hat, x) # remember you need a sigmoid on decoder out to use bce\n",
        "        # or you could use torch.nn.functional.binary_cross_entropy_with_logits without the sigmoid\n",
        "        kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "        scrunch_factor = 1e-3 # larger means blurrier/blobbier\n",
        "        rescaled_kl_loss = (kl_loss * scrunch_factor) # this is what goes in the loss function\n",
        "        loss = recon_loss + rescaled_kl_loss\n",
        "\n",
        "        self.log(f'{log_prefix}loss', loss, prog_bar=True)\n",
        "        self.log(f'{log_prefix}recon_loss', recon_loss)\n",
        "        self.log(f'{log_prefix}kl_loss', kl_loss)\n",
        "        self.log(F'{log_prefix}rescaled_kl_loss', rescaled_kl_loss)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.pred_and_log(batch, batch_idx, log_prefix='train/')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.pred_and_log(batch, batch_idx, log_prefix='val/')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=5e-4)\n",
        "\n",
        "    def on_epoch_start(self): # give us a new line for each epoch\n",
        "        print('\\n')\n",
        "\n",
        "    def on_validation_epoch_end(self, demo_every=1):\n",
        "        if self.current_epoch % demo_every == 0:  # log every this many epochs\n",
        "            fig = test_inference(self, idx=range(5), return_fig=True)\n",
        "            self.logger.experiment.log({\"reconstructions\": wandb.Image(fig), \"epoch\": self.current_epoch})\n",
        "            plt.close(fig)  # clean up\n",
        "\n",
        "\n",
        "vae = VAEModel()\n",
        "model = vae"
      ],
      "metadata": {
        "id": "wwJZ93lr5xb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "# Lightning defines its own WandbLogger callback...\n",
        "wandb.finish() # just in case we're aborting runs & restarting\n",
        "\n",
        "# set up the logging\n",
        "wandb_logger = WandbLogger(log_model=\"all\", project='vae_sim')\n",
        "try:\n",
        "    wandb_logger.watch(model)\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "P7rbL7Wi6Xxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25  # VAEs require more steps to train than vanilla AEs, due to dual-objective loss\n",
        "trainer = L.Trainer(max_epochs=epochs, devices=\"auto\", logger=wandb_logger, callbacks=RichProgressBar(leave=True))\n",
        "trainer.fit(model=vae, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "vtL3uxhtPknL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}